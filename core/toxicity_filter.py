# core/toxicity_filter.py
import asyncio
from typing import Dict, List, Tuple
from dataclasses import dataclass
import re
import logging

logger = logging.getLogger(__name__)

@dataclass
class ToxicityResult:
    is_toxic: bool
    confidence: float
    reason: str
    detected_patterns: List[str]
    safe_response: str = "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ –º–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ."

class ToxicityFilter:
    """
    üõ°Ô∏è –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –¢–û–ö–°–ò–ß–ù–´–• –ò –ù–ï–ü–û–î–•–û–î–Ø–©–ò–• –°–û–û–ë–©–ï–ù–ò–ô
    """
    
    def __init__(self, config):
        self.config = config
        self._patterns = self._compile_patterns()
        self._safe_responses = [
            "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ –º–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ.",
            "–î–∞–≤–∞–π—Ç–µ –æ–±—Å—É–¥–∏–º –≤–æ–ø—Ä–æ—Å—ã –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö —É—Å–ª—É–≥ –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥–∞.",
            "–Ø –∑–¥–µ—Å—å, —á—Ç–æ–±—ã –ø–æ–º–æ—á—å —Å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –≥–æ—Å—É—Å–ª—É–≥–∞—Ö.",
        ]
    
    async def analyze(self, text: str) -> ToxicityResult:
        """–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç—å"""
        text_lower = text.lower()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º
        pattern_matches = await self._check_patterns(text_lower)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Ñ—Ä–∞–∑–∞–º
        phrase_matches = await self._check_toxic_phrases(text_lower)
        
        # –°–æ–≤–æ–∫—É–ø–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        all_matches = pattern_matches + phrase_matches
        is_toxic = len(all_matches) > 0
        confidence = min(1.0, len(all_matches) * 0.3)  # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞
        
        return ToxicityResult(
            is_toxic=is_toxic,
            confidence=confidence,
            reason="–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è" if is_toxic else "–¢–µ–∫—Å—Ç –±–µ–∑–æ–ø–∞—Å–µ–Ω",
            detected_patterns=all_matches,
            safe_response=self._get_safe_response()
        )
    
    async def _check_patterns(self, text: str) -> List[str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º"""
        matches = []
        for pattern_name, pattern in self._patterns.items():
            if pattern.search(text):
                matches.append(pattern_name)
        return matches
    
    async def _check_toxic_phrases(self, text: str) -> List[str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Å–ø–∏—Å–∫—É —Ç–æ–∫—Å–∏—á–Ω—ã—Ö —Ñ—Ä–∞–∑"""
        toxic_phrases = self.config.TOXICITY_FILTER_CONFIG.get('blocked_phrases', [])
        matches = []
        
        for phrase in toxic_phrases:
            if phrase in text:
                matches.append(f"—Ñ—Ä–∞–∑–∞: {phrase}")
        
        return matches
    
    def _compile_patterns(self) -> Dict:
        """–ö–æ–º–ø–∏–ª—è—Ü–∏—è —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏"""
        patterns = {
            '–æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è': re.compile(r'\b(–¥—É—Ä–∞–∫|–∏–¥–∏–æ—Ç|–∫—Ä–µ—Ç–∏–Ω|–¥–µ–±–∏–ª|–º—É–¥–∞–∫)\b', re.IGNORECASE),
            '–Ω–µ–Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è_–ª–µ–∫—Å–∏–∫–∞': re.compile(r'\b([–∞-—è]*—Ö[–∞-—è]*|–±–ª—è|–ø–∏–∑–¥)\w*\b', re.IGNORECASE),
            '—É–≥—Ä–æ–∑—ã': re.compile(r'\b(—É–±—å—é|–∑–∞—Ä–µ–∂—É|–∏–∑–æ–±—å—é|—Å–æ–∂–≥—É|—Ä–∞–∑–æ–±—å—é)\b', re.IGNORECASE),
            '—ç–∫—Å—Ç—Ä–µ–º–∏–∑–º': re.compile(r'\b(—Ç–µ—Ä—Ä–æ—Ä–∏–∑–º|–∏—Å–ª–∞–º—Å–∫–æ–µ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–æ|–∏—Å–ª–∞–º–∏—Å—Ç—ã)\b', re.IGNORECASE),
        }
        return patterns
    
    def _get_safe_response(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"""
        import random
        return random.choice(self._safe_responses)